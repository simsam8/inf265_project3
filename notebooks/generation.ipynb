{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')  # Add the parent directory to sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, os\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from src.utils import train, set_device, beam_search, plot_performance_over_time, compute_accuracy\n",
    "from src.models import GenerativeRNN, GenerativeLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 265\n",
    "torch.manual_seed(SEED)\n",
    "DEVICE = set_device(\"cuda\")\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_GENERATED = \"../generated_data/\"\n",
    "mapping = torch.load(PATH_GENERATED + \"mapping.pt\")\n",
    "embedding = torch.load(PATH_GENERATED + \"embedding_matrix.pt\")\n",
    "vocab = torch.load(PATH_GENERATED + \"vocabulary.pt\")\n",
    "words_train = torch.load(PATH_GENERATED + \"words_train.pt\")\n",
    "words_val = torch.load(PATH_GENERATED + \"words_val.pt\")\n",
    "words_test = torch.load(PATH_GENERATED + \"words_test.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset for text generation\n",
    "def create_dataset(text, vocab, context_size, map_target=None):\n",
    "    \"\"\"\n",
    "    Create a pytorch dataset of context / target pairs from a text\n",
    "    \"\"\"\n",
    "\n",
    "    n_text = len(text)\n",
    "    n_vocab = len(vocab)\n",
    "\n",
    "    if map_target is None:\n",
    "        map_target = {i: i for i in range(n_vocab)}\n",
    "\n",
    "    txt = [vocab[w] for w in text]\n",
    "\n",
    "    contexts = []\n",
    "    targets = []\n",
    "\n",
    "    for i in range(context_size, n_text):\n",
    "\n",
    "        t = txt[i]\n",
    "        # exclude <unk>(0) and/or punctuation(1) from targets\n",
    "        if map_target[t] in [\"<unk>\", \",\", \".\", \"(\", \")\", \"?\", \"!\"]:\n",
    "            pass\n",
    "        else:\n",
    "            # Contex before target\n",
    "            c = txt[i - context_size : i]\n",
    "            targets.append(t)\n",
    "            contexts.append(torch.tensor(c))\n",
    "\n",
    "    # contexts of shape (N_dataset, contexts_size)\n",
    "    # targets of shape (N_dataset)\n",
    "    contexts = torch.stack(contexts)\n",
    "    targets = torch.tensor(targets)\n",
    "    return TensorDataset(contexts, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTEXT_SIZE = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(PATH_GENERATED + \"text_generation_data.pt\"):\n",
    "    data_train, data_val, data_test = torch.load(PATH_GENERATED+\"text_generation_data.pt\")\n",
    "else:\n",
    "    data_train = create_dataset(words_train, vocab, CONTEXT_SIZE, mapping)\n",
    "    data_val = create_dataset(words_val, vocab, CONTEXT_SIZE, mapping)\n",
    "    data_test = create_dataset(words_test, vocab, CONTEXT_SIZE, mapping)\n",
    "    torch.save((data_train, data_val, data_test), PATH_GENERATED+\"text_generation_data.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "n_epochs = 2\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "print(f\"-- Global Parameters --\")\n",
    "print(f\"{batch_size=}\")\n",
    "print(f\"{n_epochs=}\")\n",
    "print(f\"{CONTEXT_SIZE=}\") \n",
    "\n",
    "model_architectures = [GenerativeRNN, GenerativeLSTM]\n",
    "# Each model parameter corresponds to the architecture at the same position\n",
    "model_parameters = [\n",
    "    [\n",
    "        {\"num_hiddens\": 8, \"num_layers\": 4, \"dropout\": 0},   \n",
    "        # {\"num_hiddens\": 16, \"num_layers\": 8, \"dropout\": 0.1},   \n",
    "    ],\n",
    "    [\n",
    "        {\"num_hiddens\": 8, \"num_layers\": 4, \"dropout\": 0},   \n",
    "        # {\"num_hiddens\": 16, \"num_layers\": 8, \"dropout\": 0.1},   \n",
    "    ]\n",
    "]\n",
    "parameter_search = [\n",
    "    {\"lr\":0.008},\n",
    "    # {\"lr\":0.001},\n",
    "    # {\"lr\":0.01},\n",
    "    # {\"lr\":0.0005},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(data_train, batch_size=batch_size)\n",
    "val_loader = DataLoader(data_val, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accs = []\n",
    "val_accs = []\n",
    "val_perfs = []\n",
    "models = []\n",
    "\n",
    "if os.path.isfile(PATH_GENERATED + \"text_generation_model.pt\"):\n",
    "    print(\"Skipping training, loading existing model...\")\n",
    "else:\n",
    "    for architecture, m_params in zip(model_architectures, model_parameters):\n",
    "        for params in parameter_search:\n",
    "            print(\"\\n-- Training with following parameters --:\")\n",
    "            print(\"\\nModel architecture: \", architecture)\n",
    "            for name, val in params.items():\n",
    "                print(f\"{name}: {val}\")\n",
    "            for m_param in m_params:\n",
    "                print(m_param)\n",
    "                \n",
    "                embedding = embedding.to(DEVICE)\n",
    "                torch.manual_seed(SEED)\n",
    "                model = architecture(embedding, **m_param)\n",
    "                model.to(DEVICE)\n",
    "                optimizer = Adam(model.parameters(), lr=params[\"lr\"])\n",
    "    \n",
    "                train_loss, val_loss, train_acc, val_acc = train(n_epochs, model, optimizer, loss_fn, train_loader, val_loader, DEVICE)\n",
    "                \n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                train_accs.append(train_acc)\n",
    "                val_accs.append(val_acc)\n",
    "                val_perfs.append(val_acc[-1])\n",
    "                models.append(model)\n",
    "                print(f\"Train accuracy: {train_acc[-1]*100:.3f}%\")\n",
    "                print(f\"Validation accuracy: {val_acc[-1]*100:.3f}%\\n\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(PATH_GENERATED + \"text_generation_model.pt\"):\n",
    "    chosen_model = torch.load(PATH_GENERATED + \"text_generation_model.pt\")\n",
    "    chosen_index, train_losses, val_losses, train_accs, val_accs = torch.load(PATH_GENERATED + \"text_generation_plots.pt\")\n",
    "else:\n",
    "    chosen_index = val_perfs.index(max(val_perfs))\n",
    "    chosen_model = models[chosen_index]\n",
    "    torch.save(chosen_model, PATH_GENERATED + \"text_generation_model.pt\")\n",
    "    torch.save((chosen_index, train_losses, val_losses, train_accs, val_accs), PATH_GENERATED + \"text_generation_plots.pt\")\n",
    "print(chosen_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_performance_over_time(train_losses[chosen_index], val_losses[chosen_index],\n",
    "                           \"Training and Validation loss of chosen model\", \"loss\",\n",
    "                            f_name=\"../images/text_generation_loss.png\", save=True)\n",
    "plot_performance_over_time(train_accs[chosen_index], val_accs[chosen_index],\n",
    "                           \"Training and Validation accuracy of chosen model\", \"accuracy\",\n",
    "                            f_name=\"../images/text_generation_accuracy.png\", save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(data_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = compute_accuracy(chosen_model, test_loader, device=DEVICE)\n",
    "print(f\"Test accuracy: {test_acc*100:.3f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beam Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')  # Add the parent directory to sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, os\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from src.utils import train, set_device, beam_search, plot_performance_over_time, compute_accuracy\n",
    "from src.models import GenerativeRNN, GenerativeLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 265\n",
    "torch.manual_seed(SEED)\n",
    "DEVICE = set_device(\"cuda\")\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a model\n",
    "model = torch.load(\"../generated_data/text_generation_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a test sequence\n",
    "vocab = torch.load(\"../generated_data/vocabulary.pt\")\n",
    "# test_seq = [\"the\", \"cat\", \"jumped\", \"over\"]\n",
    "test_seq = [\"what\", \"is\", \"the\", \"meaning\", \"of\"]\n",
    "# test_seq = [\"i\", \"have\", \"never\"]\n",
    "# test_seq = [\"the\", \"woman\", \"was\", \"sitting\"]\n",
    "# test_seq = [\"as\", \"i\", \"opened\", \"the\"]\n",
    "test_seq = [\"to\", \"be\", \"or\", \"not\", \"to\", \"be\", \"?\"]\n",
    "test_seq = \"a king and queen once upon a time\".split()  # Exists in the training data\n",
    "\n",
    "test_seq_indeces = [vocab[token] for token in test_seq]\n",
    "print(test_seq_indeces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_seq = beam_search(model, test_seq_indeces, beam_width=10, max_len=10, print_search_tree=True)\n",
    "mapping = torch.load(\"../generated_data/mapping.pt\")\n",
    "gen_seq_to_text = [mapping[token_i] for token_i in gen_seq[0]]\n",
    "print(\"\\n\\nGenerated sequence: \", gen_seq_to_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
