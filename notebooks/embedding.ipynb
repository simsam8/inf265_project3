{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31b3cdf-2c4c-4cf6-b08e-88813dda4828",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')  # Add the parent directory to sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438179b5-646b-413f-a40a-a0ca59757c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, glob, torch\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.utils.data import TensorDataset\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torch.optim import Adam\n",
    "from datetime import datetime\n",
    "from matplotlib import pyplot as plt\n",
    "from src.models import CBOW, CBOWDeep\n",
    "from src.utils import train, compute_accuracy, set_device, plot_performance_over_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a2ab96-dfa5-4a88-ba03-27f019ea8fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 265\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "DEVICE = set_device(\"cuda\")\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda52a3d-c2fd-4f1c-90b3-f4b234f629ae",
   "metadata": {},
   "source": [
    "# Tokenization and creation of datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0dadfec-a34c-4791-8820-5b814814d1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKENIZER_EN = get_tokenizer(\"basic_english\")\n",
    "PATH_GENERATED = \"../generated_data/\"\n",
    "MIN_FREQ = 90\n",
    "DEBUGGING = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5257b3-0b34-472f-961a-6b0220f39ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_files(datapath=\"../data/data_train/\", debug=DEBUGGING):\n",
    "    files = glob.glob(datapath + \"*.txt\")\n",
    "    if debug:\n",
    "        files = files[:1]\n",
    "\n",
    "    lines = []\n",
    "    for f_name in files:\n",
    "        with open(f_name, encoding=\"UTF-8\") as f:\n",
    "            lines += f.readlines()\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4bf6b6-90b7-4f4b-a71f-9313aebc26b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(lines, tokenizer=TOKENIZER_EN):\n",
    "    list_text = []\n",
    "    for line in lines:\n",
    "        list_text += tokenizer(line)\n",
    "    return list_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08402a7-e3c8-4528-a4c2-d2e183b173e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yield_tokens(lines, tokenizer=TOKENIZER_EN):\n",
    "    no_digits = \"\\w*[0-9]+\\w*\"\n",
    "    no_names = \"\\w*[A-Z]+\\w*\"\n",
    "    no_spaces = \"\\s+\"\n",
    "\n",
    "    for line in lines:\n",
    "        line = re.sub(no_digits, \" \", line)\n",
    "        line = re.sub(no_names, \" \", line)\n",
    "        line = re.sub(no_spaces, \" \", line)\n",
    "        yield tokenizer(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6cc1a5-e687-41f9-8699-1fd49cce6868",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_freqs(words, vocab):\n",
    "    freqs = torch.zeros(len(vocab), dtype=torch.int)\n",
    "    for w in words:\n",
    "        freqs[vocab[w]] += 1\n",
    "    return freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf03b82e-fd51-4756-819d-38ef0191ee49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vocabulary(lines, min_freq=MIN_FREQ):\n",
    "    vocab = build_vocab_from_iterator(\n",
    "        yield_tokens(lines), min_freq=min_freq, specials=[\"<unk>\"]\n",
    "    )\n",
    "    vocab.append_token(\"i\")\n",
    "    vocab.set_default_index(vocab[\"<unk>\"])\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac64b1e-7ea9-42cb-a6f1-dbf2b502c83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize texts\n",
    "# Load tokenized texts if they are generated\n",
    "# else, create it and save it\n",
    "\n",
    "if os.path.isfile(PATH_GENERATED + \"words_train.pt\"):\n",
    "    words_train = torch.load(PATH_GENERATED + \"words_train.pt\")\n",
    "    words_val = torch.load(PATH_GENERATED + \"words_val.pt\")\n",
    "    words_test = torch.load(PATH_GENERATED + \"words_test.pt\")\n",
    "else:\n",
    "    lines_book_train = read_files(\"../data/data_train/\")\n",
    "    lines_book_val = read_files(\"../data/data_val/\")\n",
    "    lines_book_test = read_files(\"../data/data_test/\")\n",
    "\n",
    "    words_train = tokenize(lines_book_train)\n",
    "    words_val = tokenize(lines_book_val)\n",
    "    words_test = tokenize(lines_book_test)\n",
    "\n",
    "    torch.save(words_train, PATH_GENERATED + \"words_train.pt\")\n",
    "    torch.save(words_val, PATH_GENERATED + \"words_val.pt\")\n",
    "    torch.save(words_test, PATH_GENERATED + \"words_test.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9b4720-6b5b-41cc-ab7e-c34fbb658217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vocabulary\n",
    "\n",
    "VOCAB_FNAME = \"vocabulary.pt\"\n",
    "\n",
    "if os.path.isfile(PATH_GENERATED + VOCAB_FNAME):\n",
    "    vocab = torch.load(PATH_GENERATED + VOCAB_FNAME)\n",
    "else:\n",
    "    vocab = create_vocabulary(lines_book_train, min_freq=MIN_FREQ)\n",
    "    torch.save(vocab, PATH_GENERATED + VOCAB_FNAME)\n",
    "    vocab_df = pd.DataFrame([w for w in vocab.lookup_tokens(range(len(vocab)))])\n",
    "    vocab_df.to_csv(PATH_GENERATED+\"vocab.tsv\", sep=\"\\t\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83448f96-53e3-4570-b735-4b138f2145f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis\n",
    "\n",
    "VOCAB_SIZE = len(vocab)\n",
    "print(\"Total number of words in the training dataset:     \", len(words_train))\n",
    "print(\"Total number of words in the validation dataset:   \", len(words_val))\n",
    "print(\"Total number of words in the test dataset:         \", len(words_test))\n",
    "print(\"Number of distinct words in the training dataset:  \", len(set(words_train)))\n",
    "print(\"Number of distinct words in the validation dataset:  \", len(set(words_val)))\n",
    "print(\"Number of distinct words in the test dataset:  \", len(set(words_test)))\n",
    "print(\"Number of distinct words kept (vocabulary size):   \", VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da381e7b-0587-4b5a-a61e-44f64efed6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIGHTS_FNAME = \"class_weights.pt\"\n",
    "\n",
    "# Calculate vocab frequencies and store vocab weights\n",
    "if os.path.isfile(PATH_GENERATED + WEIGHTS_FNAME):\n",
    "    weights = torch.load(PATH_GENERATED + WEIGHTS_FNAME)\n",
    "else:\n",
    "    freqs = count_freqs(words_train, vocab)\n",
    "    weights = 1 / freqs\n",
    "    torch.save(weights, PATH_GENERATED + \"class_weights.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fc6973-eff7-4dcb-a7a9-2fead183880d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define targets\n",
    "\n",
    "MAPPING_FNAME = \"mapping.pt\"\n",
    "# true labels for this task:\n",
    "if os.path.isfile(PATH_GENERATED + MAPPING_FNAME):\n",
    "    MAP_TARGET = torch.load(PATH_GENERATED + MAPPING_FNAME)\n",
    "else:\n",
    "    MAP_TARGET = {vocab[w]: w for w in vocab.lookup_tokens(range(VOCAB_SIZE))}\n",
    "    torch.save(MAP_TARGET, PATH_GENERATED + \"mapping.pt\")\n",
    "\n",
    "# context size for behind and after target\n",
    "CONTEXT_SIZE = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64bfb7d-39d0-4067-94a0-3803f5e6d5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(text, vocab, context_size=CONTEXT_SIZE, map_target=MAP_TARGET):\n",
    "    \"\"\"\n",
    "    Create a pytorch dataset of context / target pairs from a text\n",
    "    \"\"\"\n",
    "\n",
    "    n_text = len(text)\n",
    "    n_vocab = len(vocab)\n",
    "\n",
    "    if map_target is None:\n",
    "        map_target = {i: i for i in range(n_vocab)}\n",
    "\n",
    "    txt = [vocab[w] for w in text]\n",
    "\n",
    "    contexts = []\n",
    "    targets = []\n",
    "\n",
    "    for i in range(context_size, n_text - context_size):\n",
    "\n",
    "        t = txt[i]\n",
    "        # exclude <unk>(0) and/or punctuation(1) from targets\n",
    "        if map_target[t] in [\"<unk>\", \",\", \".\", \"(\", \")\", \"?\", \"!\"]:\n",
    "            pass\n",
    "        else:\n",
    "            c = txt[i - context_size : i] + txt[i + 1 : i + context_size + 1]\n",
    "            targets.append(t)\n",
    "            contexts.append(torch.tensor(c))\n",
    "\n",
    "    # contexts of shape (N_dataset, contexts_size)\n",
    "    # targets of shape (N_dataset)\n",
    "    contexts = torch.stack(contexts)\n",
    "    targets = torch.tensor(targets)\n",
    "    return TensorDataset(contexts, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6457e104-2459-4788-8b2d-f7bab9368fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(words, vocab, fname):\n",
    "    \"\"\"\n",
    "    Load dataset if already generated, otherwise, create it and save it.\n",
    "    \"\"\"\n",
    "    if os.path.isfile(PATH_GENERATED + fname):\n",
    "        dataset = torch.load(PATH_GENERATED + fname)\n",
    "    else:\n",
    "        dataset = create_dataset(words, vocab)\n",
    "        torch.save(dataset, PATH_GENERATED + fname)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffe2230-8270-4dc6-bc0a-4599ccf36578",
   "metadata": {},
   "source": [
    "# Training embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63dcbd66-5097-4d2a-adb5-8f6cea1ded54",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = load_dataset(words_train, vocab, \"data_train.pt\")\n",
    "data_val = load_dataset(words_val, vocab, \"data_val.pt\")\n",
    "data_test = load_dataset(words_test, vocab, \"data_test.pt\")\n",
    "\n",
    "print(f\"Context, target pairs in training set: {len(data_train)}\")\n",
    "print(f\"Context, target pairs in validation set: {len(data_val)}\")\n",
    "print(f\"Context, target pairs in test set: {len(data_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7927818-6255-42b3-8cc9-a5671cf0c38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = torch.load(PATH_GENERATED+\"/vocabulary.pt\")\n",
    "vocab_weights = torch.load(PATH_GENERATED+\"/class_weights.pt\")\n",
    "vocab_weights = vocab_weights.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3398bddc-35c5-474e-ba85-79bf752e8c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "n_epochs = 15\n",
    "loss_fn = nn.NLLLoss(weight=vocab_weights)\n",
    "\n",
    "print(f\"-- Global Parameters --\")\n",
    "print(f\"{batch_size=}\")\n",
    "print(f\"{n_epochs=}\")\n",
    "\n",
    "model_architectures = [CBOW, CBOWDeep]\n",
    "\n",
    "parameter_search = [\n",
    "    {\"lr\":0.001, \"embedding_dim\": 16},\n",
    "    {\"lr\":0.001, \"embedding_dim\": 20},\n",
    "    {\"lr\":0.008, \"embedding_dim\": 16},\n",
    "    {\"lr\":0.008, \"embedding_dim\": 20},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c62c1e-69d3-4628-9236-4cc3ccbe6635",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(data_train, batch_size=batch_size)\n",
    "val_loader = DataLoader(data_val, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e32815-2409-4962-866b-dd73c74b0259",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(PATH_GENERATED + \"embedding_model.pt\"):\n",
    "    print(\"Skipping training, loading existing model...\")\n",
    "else:\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accs = []\n",
    "    val_accs = []\n",
    "    val_perf = []\n",
    "    hyper_params = []\n",
    "    models = []\n",
    "    \n",
    "    for architecture in model_architectures:\n",
    "        for params in parameter_search:\n",
    "            print(\"\\n-- Training with following parameters --:\")\n",
    "            print(f\"{architecture=}\")\n",
    "            for name, val in params.items():\n",
    "                print(f\"{name}: {val}\")\n",
    "            torch.manual_seed(SEED)\n",
    "            model = architecture(len(vocab), CONTEXT_SIZE, params[\"embedding_dim\"])\n",
    "            model.to(DEVICE)\n",
    "            optimizer = Adam(model.parameters(), lr=params[\"lr\"])\n",
    "            \n",
    "            train_loss, val_loss, train_acc, val_acc = train(n_epochs, model, optimizer, loss_fn, train_loader, val_loader, DEVICE)\n",
    "            train_losses.append(train_loss)\n",
    "            val_losses.append(val_loss)\n",
    "            train_accs.append(train_acc)\n",
    "            val_accs.append(val_acc)\n",
    "            val_perf.append(val_acc[-1])\n",
    "            hyper_params.append({\"architecture\": architecture, **params})\n",
    "            models.append(model)\n",
    "            print(f\"Train accuracy: {train_acc[-1]*100:.3f}%\")\n",
    "            print(f\"Validation accuracy: {val_acc[-1]*100:.3f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b21ff6-f1a2-4a5e-ae08-fae1809a00dd",
   "metadata": {},
   "source": [
    "# Embedding selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf1f0c4-ce2f-4fe4-8e29-7d13bf141cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(PATH_GENERATED + \"embedding_model.pt\"):\n",
    "    chosen_model = torch.load(PATH_GENERATED + \"embedding_model.pt\")\n",
    "    chosen_index, train_losses, val_losses, train_accs, val_accs, hyper_params = torch.load(PATH_GENERATED + \"embedding_plots.pt\")\n",
    "else:\n",
    "    chosen_index = val_perf.index(max(val_perf))\n",
    "    chosen_model = models[chosen_index]\n",
    "    torch.save(chosen_model, PATH_GENERATED + \"embedding_model.pt\")\n",
    "    torch.save(chosen_model.embedding, PATH_GENERATED+\"embedding_matrix.pt\")\n",
    "    torch.save((chosen_index, train_losses, val_losses, train_accs, val_accs, hyper_params), PATH_GENERATED + \"embedding_plots.pt\")\n",
    "    \n",
    "    embedding_frame = pd.DataFrame(chosen_model.embedding.weight.to(\"cpu\").detach()).astype(\"float64\")\n",
    "    embedding_frame.to_csv(PATH_GENERATED+\"embedding.tsv\", sep=\"\\t\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58624bf4-361c-454c-a89c-fa2a4c9e9032",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Chosen parameters: \")\n",
    "print(hyper_params[chosen_index])\n",
    "print(\"\\nChosen model: \")\n",
    "print(chosen_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596ce5ff-d36c-4aed-b7e8-a8e5c0ca3a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_performance_over_time(train_losses[chosen_index], val_losses[chosen_index],\n",
    "                           \"Training and Validation loss of chosen model\", \"loss\",\n",
    "                            f_name=\"../images/embedding_loss.png\", save=True)\n",
    "plot_performance_over_time(train_accs[chosen_index], val_accs[chosen_index],\n",
    "                           \"Training and Validation accuracy of chosen model\", \"accuracy\",\n",
    "                            f_name=\"../images/embedding_accuracy.png\", save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8675e125-5a77-484c-b58c-e16ff0b0343c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(data_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce19ec56-43c5-40a8-bba0-83559bf6544f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = compute_accuracy(chosen_model, test_loader, device=DEVICE)\n",
    "print(f\"Test accuracy: {test_acc*100:.3f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf33db13-3a94-4e2b-b5f5-bf2f73849fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = MAP_TARGET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08eacff4-84ee-4e45-a80a-c6f2ac8cdda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cos = nn.CosineSimilarity(dim=1)\n",
    "embedding = chosen_model.embedding.weight.clone()\n",
    "\n",
    "print(\"-- 10 most similar words --\")\n",
    "words = [\"me\", \"white\", \"man\", \"woman\", \"brain\", \"have\", \"be\", \"child\", \"yes\", \"castle\", \"greatest\", \"gentleman\", \"clothes\"]\n",
    "for word in words:\n",
    "    vocab_index = vocab[word]\n",
    "    similarity = cos(embedding[vocab_index].view(1, -1), embedding)\n",
    "    idx_ten = torch.topk(similarity, 11).indices\n",
    "    most_similar = [mapping[int(i)] for i in idx_ten][1:] #  Exclude similarity with itself\n",
    "    if vocab_index == 0:\n",
    "        print(f\"{word}({mapping[int(vocab_index)]}): {most_similar}\")\n",
    "    else:\n",
    "        print(f\"{word}: {most_similar}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea96806-3c87-4cb7-babe-3a0ede2d2829",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similarity_matrix(a, b, eps=1e-8):\n",
    "    \"\"\"\n",
    "    added eps for numerical stability\n",
    "    \"\"\"\n",
    "    a_n, b_n = a.norm(dim=1)[:, None], b.norm(dim=1)[:, None]\n",
    "    a_norm = a / torch.max(a_n, eps * torch.ones_like(a_n))\n",
    "    b_norm = b / torch.max(b_n, eps * torch.ones_like(b_n))\n",
    "    sim_mt = torch.mm(a_norm, b_norm.transpose(0, 1))\n",
    "    return sim_mt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e447ff-54af-4b97-9ee9-4de8d08ccfc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_matrix = calculate_similarity_matrix(embedding, embedding)\n",
    "plt.matshow(sim_matrix.detach().to(\"cpu\"))\n",
    "plt.colorbar()\n",
    "plt.title(\"Cosine similarity matrix\")\n",
    "plt.xlabel(\"Vocab index\")\n",
    "plt.ylabel(\"Vocab index\")\n",
    "plt.savefig(\"../images/similarity_matrix.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
