{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf87eb3-c273-487f-9cdf-e12cff913286",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be59fefb-afe7-45b4-b807-2e3de1d20ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "from src.utils import train, compute_accuracy, set_device, plot_performance_over_time\n",
    "from src.models import SimpleMLP, AttentionMLP, ConjugationRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c6e24f-954e-4a7f-b28d-07eb9021a77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 265\n",
    "torch.manual_seed(SEED)\n",
    "DEVICE = set_device(\"cuda\")\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e74a3ae-e2c1-4ff7-8c5c-6c0f8b424321",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = torch.load(\"generated_data/data_train.pt\")\n",
    "data_val = torch.load(\"generated_data/data_val.pt\")\n",
    "data_test = torch.load(\"generated_data/data_test.pt\")\n",
    "mapping = torch.load(\"generated_data/mapping.pt\")\n",
    "embedding = torch.load(\"generated_data/embedding_matrix.pt\")\n",
    "vocab = torch.load(\"generated_data/vocabulary.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65341b12-f17d-442f-a157-7039ff61062e",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [data_train, data_val, data_test]\n",
    "target_filter  = [\"be\", \"am\", \"are\", \"is\", \"was\", \"were\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\"]\n",
    "target_map = {vocab[w]: i for i, w in enumerate(target_filter)}\n",
    "\n",
    "for i, dataset in enumerate(datasets):\n",
    "    filtered_tensors = []\n",
    "    for context, target in dataset:\n",
    "        if mapping[int(target)] in target_filter:\n",
    "            filtered_tensors.append((context, torch.tensor(target_map[int(target)])))\n",
    "    filtered_tensors = list(zip(*filtered_tensors))\n",
    "    filtered_tensors = TensorDataset(*[torch.stack(t) for t in filtered_tensors])\n",
    "    datasets[i] = filtered_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252a9dde-73b4-4439-9782-f3c5c4869c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_val, data_test = datasets\n",
    "print(\"Size of training data: \", len(data_train))\n",
    "print(\"Size of validation data: \", len(data_val))\n",
    "print(\"Size of test data: \", len(data_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957c0f73-6dd9-49b8-9be9-e8a44137b303",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_size = int(data_train[0][0].shape[0])\n",
    "batch_size = 64\n",
    "n_epochs = 15\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "print(f\"-- Global Parameters --\")\n",
    "print(f\"{batch_size=}\")\n",
    "print(f\"{n_epochs=}\")\n",
    "print(f\"{context_size=}\")\n",
    "\n",
    "model_architectures = [SimpleMLP, AttentionMLP, ConjugationRNN]\n",
    "parameter_search = [\n",
    "    {\"lr\":0.008},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edbf007-7eb6-4019-841a-203400eb3ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(data_train, batch_size=batch_size)\n",
    "val_loader = DataLoader(data_val, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e32815-2409-4962-866b-dd73c74b0259",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accs = []\n",
    "val_accs = []\n",
    "val_perfs = []\n",
    "models = []\n",
    "\n",
    "for params in parameter_search:\n",
    "    print(\"\\n-- Training with following parameters --:\")\n",
    "    for architecture in model_architectures:\n",
    "        print(\"\\nModel architecture: \", architecture)\n",
    "        for name, val in params.items():\n",
    "            print(f\"{name}: {val}\")\n",
    "\n",
    "        embedding = embedding.to(DEVICE)\n",
    "        torch.manual_seed(SEED)\n",
    "        model = architecture(embedding, max_len=context_size)\n",
    "        model.to(DEVICE)\n",
    "        optimizer = Adam(model.parameters(), lr=params[\"lr\"])\n",
    "        \n",
    "        train_loss, val_loss, train_acc, val_acc = train(n_epochs, model, optimizer, loss_fn, train_loader, val_loader, DEVICE)\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        train_accs.append(train_acc)\n",
    "        val_accs.append(val_acc)\n",
    "        val_perfs.append(val_acc[-1])\n",
    "        models.append(model)\n",
    "        print(f\"Train accuracy: {train_acc[-1]*100:.3f}%\")\n",
    "        print(f\"Validation accuracy: {val_acc[-1]*100:.3f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a853e8-912d-4fad-b9f9-7558121487ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_index = val_perfs.index(max(val_perfs))\n",
    "chosen_model = models[chosen_index]\n",
    "print(chosen_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2efb4f2-21dc-457d-b75c-8b6c058aa928",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_performance_over_time(train_losses[chosen_index], val_losses[chosen_index], \"Training and Validation loss of chosen model\", \"loss\")\n",
    "plot_performance_over_time(train_accs[chosen_index], val_accs[chosen_index], \"Training and Validation accuracy of chosen model\", \"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98eb0521-316e-4e19-aaf5-3450f3b49e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(data_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5987543-5c36-4e2e-a357-32104f4b926c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = compute_accuracy(chosen_model, test_loader, device=DEVICE)\n",
    "print(f\"Test accuracy: {test_acc*100:.3f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
