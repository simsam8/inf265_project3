{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf87eb3-c273-487f-9cdf-e12cff913286",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')  # Add the parent directory to sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be59fefb-afe7-45b4-b807-2e3de1d20ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, os, torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "from src.utils import train, compute_accuracy, set_device, plot_performance_over_time, plot_training_times\n",
    "from src.models import SimpleMLP, AttentionMLP, ConjugationRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c6e24f-954e-4a7f-b28d-07eb9021a77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 265\n",
    "torch.manual_seed(SEED)\n",
    "DEVICE = set_device(\"cuda\")\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e74a3ae-e2c1-4ff7-8c5c-6c0f8b424321",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_GENERATED = \"../generated_data/\"\n",
    "data_train = torch.load(PATH_GENERATED + \"data_train.pt\")\n",
    "data_val = torch.load(PATH_GENERATED + \"data_val.pt\")\n",
    "data_test = torch.load(PATH_GENERATED + \"data_test.pt\")\n",
    "mapping = torch.load(PATH_GENERATED + \"mapping.pt\")\n",
    "embedding = torch.load(PATH_GENERATED + \"embedding_matrix.pt\")\n",
    "vocab = torch.load(PATH_GENERATED + \"vocabulary.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65341b12-f17d-442f-a157-7039ff61062e",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [data_train, data_val, data_test]\n",
    "target_filter  = [\"be\", \"am\", \"are\", \"is\", \"was\", \"were\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\"]\n",
    "target_map = {vocab[w]: i for i, w in enumerate(target_filter)}\n",
    "\n",
    "if os.path.isfile(PATH_GENERATED + \"conjugation_data.pt\"):\n",
    "    datasets = torch.load(PATH_GENERATED + \"conjugation_data.pt\")\n",
    "else:\n",
    "    for i, dataset in enumerate(datasets):\n",
    "        filtered_tensors = []\n",
    "        for context, target in dataset:\n",
    "            if mapping[int(target)] in target_filter:\n",
    "                filtered_tensors.append((context, torch.tensor(target_map[int(target)])))\n",
    "        filtered_tensors = list(zip(*filtered_tensors))\n",
    "        filtered_tensors = TensorDataset(*[torch.stack(t) for t in filtered_tensors])\n",
    "        datasets[i] = filtered_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252a9dde-73b4-4439-9782-f3c5c4869c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_val, data_test = datasets\n",
    "print(\"Size of training data: \", len(data_train))\n",
    "print(\"Size of validation data: \", len(data_val))\n",
    "print(\"Size of test data: \", len(data_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957c0f73-6dd9-49b8-9be9-e8a44137b303",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_size = int(data_train[0][0].shape[0])\n",
    "batch_size = 64\n",
    "n_epochs = 30\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "print(f\"-- Global Parameters --\")\n",
    "print(f\"{batch_size=}\")\n",
    "print(f\"{n_epochs=}\")\n",
    "print(f\"{context_size=}\") \n",
    "\n",
    "model_architectures = [SimpleMLP, AttentionMLP, ConjugationRNN]\n",
    "# Each model parameter corresponds to the architecture at the same position\n",
    "model_parameters = [\n",
    "    [\n",
    "        {\"l1\": 128, \"l2\": 32},\n",
    "        {\"l1\": 256, \"l2\": 64},\n",
    "        {\"l1\": 256, \"l2\": 256},\n",
    "    ],\n",
    "    [\n",
    "        {\"n_heads\": 4, \"w_size\": 8},\n",
    "        {\"n_heads\": 8, \"w_size\": 16},\n",
    "        {\"n_heads\": 16, \"w_size\": 20},\n",
    "    ],\n",
    "    [\n",
    "        {\"num_hiddens\": 8, \"num_layers\": 4, \"dropout\": 0},   \n",
    "        {\"num_hiddens\": 16, \"num_layers\": 8, \"dropout\": 0.1},   \n",
    "        {\"num_hiddens\": 20, \"num_layers\": 16, \"dropout\": 0.01},   \n",
    "    ]\n",
    "]\n",
    "parameter_search = [\n",
    "    {\"lr\":0.008},\n",
    "    {\"lr\":0.001},\n",
    "    {\"lr\":0.0005},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edbf007-7eb6-4019-841a-203400eb3ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(data_train, batch_size=batch_size)\n",
    "val_loader = DataLoader(data_val, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e32815-2409-4962-866b-dd73c74b0259",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(PATH_GENERATED + \"conjugation_model.pt\"):\n",
    "    print(\"Skipping training, loading existing model...\")\n",
    "else:\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accs = []\n",
    "    val_accs = []\n",
    "    val_perfs = []\n",
    "    hyper_params = []\n",
    "    models = []\n",
    "    architecture_times = []\n",
    "    \n",
    "    for architecture, m_params in zip(model_architectures, model_parameters):\n",
    "        model_times = []\n",
    "        for params in parameter_search:\n",
    "            print(\"\\n-- Training with following parameters --:\")\n",
    "            print(\"\\nModel architecture: \", architecture)\n",
    "            for name, val in params.items():\n",
    "                print(f\"{name}: {val}\")\n",
    "            for m_param in m_params:\n",
    "                print(m_param)\n",
    "                \n",
    "                embedding = embedding.to(DEVICE)\n",
    "                torch.manual_seed(SEED)\n",
    "                model = architecture(embedding, max_len=context_size, **m_param)\n",
    "                model.to(DEVICE)\n",
    "                optimizer = Adam(model.parameters(), lr=params[\"lr\"])\n",
    "    \n",
    "                start_time = time.time()\n",
    "                train_loss, val_loss, train_acc, val_acc = train(n_epochs, model, optimizer, loss_fn, train_loader, val_loader, DEVICE)\n",
    "                end_time = time.time()\n",
    "                training_time = end_time-start_time\n",
    "                model_times.append(training_time)\n",
    "                \n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                train_accs.append(train_acc)\n",
    "                val_accs.append(val_acc)\n",
    "                val_perfs.append(val_acc[-1])\n",
    "                hyper_params.append({\"architecture\": architecture, **params, **m_param})\n",
    "                models.append(model)\n",
    "                print(f\"Training time: {training_time:.3f}s\")\n",
    "                print(f\"Train accuracy: {train_acc[-1]*100:.3f}%\")\n",
    "                print(f\"Validation accuracy: {val_acc[-1]*100:.3f}%\\n\")\n",
    "        architecture_times.append(np.average(model_times))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a853e8-912d-4fad-b9f9-7558121487ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(PATH_GENERATED + \"conjugation_model.pt\"):\n",
    "    chosen_model = torch.load(PATH_GENERATED + \"conjugation_model.pt\")\n",
    "    chosen_index, architecture_times, train_losses, val_losses, train_accs, val_accs, hyper_params = torch.load(PATH_GENERATED + \"conjugation_plots.pt\")\n",
    "else:\n",
    "    chosen_index = val_perfs.index(max(val_perfs))\n",
    "    chosen_model = models[chosen_index]\n",
    "    torch.save(chosen_model, PATH_GENERATED + \"conjugation_model.pt\")\n",
    "    torch.save((chosen_index, architecture_times, train_losses, val_losses, train_accs, val_accs, hyper_params), PATH_GENERATED + \"conjugation_plots.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d1d50e-e451-4a5c-bc81-aec8480117ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Chosen parameters: \")\n",
    "print(hyper_params[chosen_index])\n",
    "print(\"\\nChosen model: \")\n",
    "print(chosen_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2efb4f2-21dc-457d-b75c-8b6c058aa928",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_times(architecture_times, [\"SimlpeMLP\", \"AttentionMLP\", \"ConjugationRNN\"],\n",
    "                    f_name=\"../images/conjugation_training_times.png\", save=True)\n",
    "plot_performance_over_time(train_losses[chosen_index], val_losses[chosen_index],\n",
    "                           \"Training and Validation loss of chosen model\", \"loss\",\n",
    "                            f_name=\"../images/conjugation_loss.png\", save=True)\n",
    "plot_performance_over_time(train_accs[chosen_index], val_accs[chosen_index],\n",
    "                           \"Training and Validation accuracy of chosen model\", \"accuracy\",\n",
    "                            f_name=\"../images/conjugation_accuracy.png\", save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98eb0521-316e-4e19-aaf5-3450f3b49e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(data_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5987543-5c36-4e2e-a357-32104f4b926c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = compute_accuracy(chosen_model, test_loader, device=DEVICE)\n",
    "print(f\"Test accuracy: {test_acc*100:.3f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
